--------- Instructions --------------


**************
CRAB templates available:

- template_crab_caf_copyToCastor.cfg 
submit from caf, copy output on CASTOR

- template_crab_grid_copyToCastor.cfg
submit from lxplus, copy output on CASTOR

- template_crab_grid_copyToCastor_CrabServer.cfg
submit from lxplus, copy output on CASTOR, use CERN server


**************
Example of instructions for template_crab_caf_copyToCastor.cfg (similar for others)

-----------------------------
0) go to CAF from lxplus

ssh lxplus

bsub -Is -q cmsinter /bin/bash -l

---------------------------------
1) setup LCG environment and crab

source /afs/cern.ch/cms/LCG/LCG-2/UI/cms_ui_env.sh
source /afs/cern.ch/cms/ccs/wm/scripts/Crab/crab.sh

---------------------------------------------------------
2) go in your CMSSW release and set the cmssw environment

scramv1 project -n CMSSW_3_3_2_MET CMSSW CMSSW_3_3_2
cd CMSSW_3_3_2_MET/src/JetMETAnalysis/PromptAnalysis/test/submitJobsWithCrab
cmsenv

----------------------------------------------------------
3) test in local your personal treeData_cfg.py config file 

cmsRun treeData_cfg.py

-------------------------------------------------------------------------
4) THIS MIGHT BE NEEDED IF YOU USE THIS TOOL WITH A DIFFERENT CONFIG FILE 
 
Edit your CMSSW config file (here treeData_cfg.py) for submission with crab.
The only thing you should change in CMSSW condig file is the name 
of the output file; instead of the output filename 
you had before, put the string THISROOTFILE

example:

fileName = cms.string( THISROOTFILE ),	

Remember to change also the createJobsWithCrabCastor.pl file
accordingly at the line marked with #%%%%%%%%%%%%% IMPORTANT %%%%%%%%%%%%% 
(The script will be fixed to avoid this.)

----------------------------
5) create dataset input list 

Create an input list with datasets that you want to analyze. 
The format of the text file is: 

dataset_name   total_number_of_events     number_of_jobs

example (inputList.txt):

/ExpressPhysics/BeamCommissioning09-Express-v2/FEVT 100 2
/MinimumBias/BeamCommissioning09-PromptReco-v2/RECO 100 2
/MinimumBias/BeamCommissioning09-rereco_FIRSTCOLL_v1/RECO 100 2

-----------------------
6) Create the crab jobs 

Follow instructions generated by typing "./createJobsWithCrabCastor.pl" to create jobs. 

Here an example: ./createJobsWithCrabCastor.pl -d `pwd`/TestMETPFG -v Ntuples-V00-00-02-Run122314 -i inputList.txt -t template_crab_caf_copyToCastor.cfg -c treeData_cfg.py -n santanas -u MET/rootNtuples/test_25Nov09 -r 122314

NOTE: the -r option is not mandatory. You can also not specify any particular run 
(for example when you run on MC samples) and the code will handle it.

This command will create the following directory structure:

`pwd`/TestMETPFG/Ntuples-V00-00-02-Run122314_20091125_214656 (the last numbers are year-month-day-hour-min-sec)
(in the jargon here used this is the so-called "production directory" or "prodDir")

  file --> inputList.txt ( created at step 5) )
  dir  --> cfgfiles (it will contain the crab and cmssw for each crab job created on the fly) 
  dir  --> output   (it will be empty in this case since .root output files are copied automatically 
                on CASTOR dir at the end of the crab job.)
  dir  --> workdir 
       dir --> dataset_1 (i.e. ExpressPhysics__BeamCommissioning09-Express-v2__FEVT )
       dir --> dataset_2 (i.e. MinimumBias__BeamCommissioning09-PromptReco-v2__RECO )
       ....
       dir --> dataset_N

     (each of these directories is the ui working directory 
      that crab usually needs to perform his job. 
      After retrieving the output, the log files STDERR and STDOUT 
      of the cmssw jobs will be copied for each dataset in the directory "res")


In castor the following directory (and subdirectories) will be created with the right permissions
to copy files with crab on castor:

/castor/cern.ch/user/s/santanas/MET/rootNtuples/test_25Nov09/Ntuples-V00-00-02-Run122314_20091125_214656

NOTE:
After the end of the crab job ( see step 7) for details ) the .root output files will be copied in this castor directory.

rfdir /castor/cern.ch/user/s/santanas/MET/rootNtuples/test_25Nov09/Ntuples-V00-00-02-Run122314_20091125_214656

-rw-r--r--   1 santanas zh                     181394 Nov 25 20:36 ExpressPhysics__BeamCommissioning09-Express-v2__FEVT_1.root
-rw-r--r--   1 santanas zh                     176087 Nov 25 20:36 ExpressPhysics__BeamCommissioning09-Express-v2__FEVT_2.root
-rw-r--r--   1 santanas zh                     173971 Nov 25 20:35 MinimumBias__BeamCommissioning09-PromptReco-v2__RECO_1.root
-rw-r--r--   1 santanas zh                     173140 Nov 25 20:35 MinimumBias__BeamCommissioning09-PromptReco-v2__RECO_2.root
-rw-r--r--   1 santanas zh                     173864 Nov 25 20:35 MinimumBias__BeamCommissioning09-rereco_FIRSTCOLL_v1__RECO_1.root
-rw-r--r--   1 santanas zh                     173205 Nov 25 20:35 MinimumBias__BeamCommissioning09-rereco_FIRSTCOLL_v1__RECO_2.root

------------------------------------------------------------------------
7) Launch submit/getouput/etc.. commands after the creation of the jobs  

After creating the jobs you can use the script 

./postCreationCommandsWithCrab.pl 

to make the following actions (standard crab commands):

   - status
   - submit
   - getouput
   - kill
   - resubmit

The status of the jobs (crab -status) will be summarized 
automatically in one file, independetly from which action you do:

   - statusCrab.log   (the full output from the "crab -status" command)

See the help (just run ./postCreationCommandsWithCrab.pl with no options) for details.

NOTE: For the moment you can apply these actions on all the jobs created, you cannot 
specify a sub-set of the jobs. Anyway for particular cases, you can always look 
at the status report and apply by hand a specific action that you need
on a single dataset or a single job.


P.S. please give me feedback (francesco.santanastasio@cern.ch)
